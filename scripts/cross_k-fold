import os
import json
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import timm
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import StratifiedKFold
from tqdm.auto import tqdm

# Import your four variants
from models.MobileNetV4_Conv_Blur_Medium_Enhanced.models import (
    MobileNetV4_Base,
    MobileNetV4_TSM,
    MobileNetV4_Res2Net,
    MobileNetV4_Res2TSM
)

# ─── Dataset ────────────────────────────────────────────────────────────────
class SpectrogramDataset(Dataset):
    def __init__(self, files, labels, spec_dir, img_size=(224,224)):
        self.files, self.labels = files, labels
        self.spec_dir, self.img_size = spec_dir, img_size

    def __len__(self): return len(self.files)

    def __getitem__(self, idx):
        fname, lbl = self.files[idx], self.labels[idx]
        arr = np.load(os.path.join(self.spec_dir, fname))
        arr = np.repeat(arr[...,None], 3, axis=-1).astype(np.float32)
        img = torch.from_numpy(arr).permute(2,0,1).unsqueeze(0)
        img = nn.functional.interpolate(img, size=self.img_size, mode='bilinear', align_corners=False).squeeze(0)
        return img, torch.tensor(lbl, dtype=torch.float32)

# ─── Helpers ────────────────────────────────────────────────────────────────
def evaluate(model, loader, device):
    model.eval()
    ys, ps = [], []
    with torch.no_grad():
        for x,y in loader:
            x = x.to(device)
            p = model(x).cpu().numpy()
            ys.extend(y.numpy().tolist())
            ps.extend(p.tolist())
    y_true, y_score = np.array(ys), np.array(ps)
    y_pred = (y_score > 0.5).astype(int)
    return {
        "accuracy":  accuracy_score(y_true, y_pred),
        "auc":       roc_auc_score(y_true, y_score),
        "precision": precision_score(y_true, y_pred, zero_division=0),
        "recall":    recall_score(y_true, y_pred, zero_division=0),
        "f1":        f1_score(y_true, y_pred)
    }

# ─── Main ───────────────────────────────────────────────────────────────────
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--spec-dir",   required=True, help="folder of .npy specs")
    parser.add_argument("--labels-csv", required=True, help="CSV with filename,label")
    parser.add_argument("--n-splits",   type=int, default=3)
    parser.add_argument("--epochs",     type=int, default=15)
    parser.add_argument("--batch-size", type=int, default=32)
    parser.add_argument("--lr",         type=float, default=1e-3)
    parser.add_argument("--device",     default="cuda")
    args = parser.parse_args()

    # Load filenames & labels
    import pandas as pd
    df = pd.read_csv(args.labels_csv)  # columns: filename,label
    files  = df["filename"].values
    labels = df["label"].values

    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=42)

    # Prepare result containers
    model_constructors = {
        "base":   MobileNetV4_Base,
        "tsm":    MobileNetV4_TSM,
        "r2n":    MobileNetV4_Res2Net,
        "r2tsm":  MobileNetV4_Res2TSM
    }
    all_results = {name: [] for name in model_constructors}

    # Cross‐validation loop
    for fold, (tr_idx, va_idx) in enumerate(skf.split(files, labels), 1):
        print(f"\n=== Fold {fold}/{args.n_splits} ===")
        tr_ds = SpectrogramDataset(files[tr_idx], labels[tr_idx], args.spec_dir)
        va_ds = SpectrogramDataset(files[va_idx], labels[va_idx], args.spec_dir)
        tr_loader = DataLoader(tr_ds, batch_size=args.batch_size, shuffle=True)
        va_loader = DataLoader(va_ds, batch_size=args.batch_size, shuffle=False)

        for name, Constructor in model_constructors.items():
            print(f"\n{ name.upper():>6s} model")
            # Instantiate model
            model = Constructor("mobilenetv4_conv_blur_medium").to(device)
            optimizer = optim.Adam(model.parameters(), lr=args.lr)
            criterion = nn.BCELoss()

            # Train
            for ep in range(1, args.epochs+1):
                model.train()
                running_loss = 0.0
                for x,y in tr_loader:
                    x,y = x.to(device), y.to(device)
                    p = model(x)
                    loss = criterion(p, y)
                    optimizer.zero_grad(); loss.backward(); optimizer.step()
                    running_loss += loss.item() * x.size(0)
                if fold==1 and ep in (1, args.epochs):
                    print(f" Epoch {ep} train loss: {running_loss/len(tr_loader.dataset):.4f}")

            # Evaluate
            metrics = evaluate(model, va_loader, device)
            print(f" Val  AUC: {metrics['auc']:.3f}")
            all_results[name].append(metrics["auc"])

    # Summarize
    print("\n=== Cross-Validation AUC (mean ± std) ===")
    for name, aucs in all_results.items():
        mean, std = np.mean(aucs), np.std(aucs)
        print(f"{name:6s}: {mean:.3f} ± {std:.3f}")
